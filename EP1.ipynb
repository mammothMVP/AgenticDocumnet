{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b7dc0c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "connection = mysql.connector.connect(\n",
    "  host = \"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "  port = 4000,\n",
    "  user = \"2B3nARpwz82J49u.root\",\n",
    "  password = \"tpc7Iw6jTcsoavz2\",\n",
    "  database = \"TextToVector\",\n",
    "  ssl_ca = \"isrgrootx1 (2).pem\",\n",
    "  ssl_verify_cert = True,\n",
    "  ssl_verify_identity = True\n",
    ")\n",
    "\n",
    "cur = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3edf620e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mysql.connector.connection_cext.CMySQLConnection object at 0x00000155C63128D0>\n"
     ]
    }
   ],
   "source": [
    "print(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4d2f228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\llm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Jupyter-specific imports\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Set environment variable for protobuf\n",
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47ee8319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n",
      "PDF loaded successfully: scammer-agent.pdf\n"
     ]
    }
   ],
   "source": [
    "local_path = 'scammer-agent.pdf'\n",
    "if local_path:\n",
    "    loader = UnstructuredPDFLoader(file_path=local_path)\n",
    "    data = loader.load()\n",
    "    print(f'PDF loaded successfully: {local_path}')\n",
    "else:\n",
    "    print('Upload a PDF file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "487abe13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'scammer-agent.pdf'}, page_content='4 2 0 2\\n\\nt c O 1 2\\n\\n] I\\n\\nA . s c [\\n\\n1 v 0 5 6 5 1 . 0 1 4 2 : v i X r a\\n\\nVoice-Enabled AI Agents can Perform Common Scams\\n\\nRichard Fang UIUC\\n\\nDylan Bowman UIUC\\n\\nDaniel Kang UIUC\\n\\nAbstract\\n\\nRecent advances in multi-modal, highly ca- pable LLMs have enabled voice-enabled AI agents. These agents are enabling new applica- tions, such as voice-enabled autonomous cus- tomer service. However, with all AI capabili- ties, these new capabilities have the potential for dual use.\\n\\nIn this work, we show that voice-enabled AI agents can perform the actions necessary to perform common scams. To do so, we select a list of common scams collected by the govern- ment and construct voice-enabled agents with directions to perform these scams. We con- duct experiments on our voice-enabled agents and show that they can indeed perform the ac- tions necessary to autonomously perform such scams. Our results raise questions around the widespread deployment of voice-enabled AI agents.\\n\\n1\\n\\nIntroduction\\n\\nAI capabilities have advanced rapidly in the past few years. Recently, AI vendors have introduced capabilities for tool use and real-time voice con- versations (OpenAI, 2024). Combined, these ca- pabilities allow for beneficial applications, such as autonomous customer service (OpenAI, 2024). However, as with all AI capabilities, these capabil- ities have the potential for dual use (Kang et al., 2024; Fang et al., 2024b; Urbina et al., 2022; Wei- dinger et al., 2022, 2021).\\n\\nTools\\n\\nStolen funds\\n\\nBank websiteResponse\\n\\nScammer agentVictimGPT-4o\\n\\nFigure 1: Architecture diagram of a voice scammer agent.\\n\\nwork, we focus specifically on the actions needed to perform the scams and do not consider questions of persuading victims.\\n\\nWe conduct a series of experiments, showing that voice-enabled AI agents are highly capable of autonomously performing the actions needed to conduct these common scams. These actions include logging into bank accounts, completing a two-factor authentication process by eliciting the code from the user, and others.\\n\\n2 Common Scams\\n\\nPhone-based scams are incredibly prevalent. Ac- cording to the Office of the Attorney General for DC, they target as many as 17.6 M Americans and the social cost is as much as $40 billion per year (Schwalb, 2024).\\n\\nIn this work, we investigate the question: can voice-enabled AI agents perform the tasks needed to conduct common scams? We answer the ques- tion in the affirmative, showing that voice-enabled AI agents can perform common scams in real-time. To do so, we first identify a list of common scams as collected by the government (Paxton, 2024). From these scams, we designed voice- enabled AI agents with directions to conduct these scams with access to simple tools (Figure 1). In this\\n\\nThese scams typically involve a scammer calling a victim to convince them to take actions or re- veal sensitive information. Based on these actions or information, the scammer then typically steals funds from the victim. We provide a list of com- mon scams in Table 1 as provided by the Attorney General of Texas’ office (Paxton, 2024).\\n\\nPerforming these scams can require complex interactions with websites and feedback from the user. Consider a scam where the scammer steals\\n\\n1\\n\\na victim’s bank credentials and steals money by transferring it out. In order to perform this scam, the scammer must:\\n\\n1. Navigate to the bank website.\\n\\n2. Retrieve the user’s username and password.\\n\\n3. Retrieve the user’s two-factor authentication code.\\n\\n4. Navigate to the transfer page.\\n\\n5. Transfer the money.\\n\\nThe scammer must also react to any errors that may occur (e.g., a misheard password).\\n\\nAs part of the scam, the scammer must also per- suade the victim that the scammer is legitimate. In this work, we do not focus on the persuasion aspect of the scam. We instead focus specifically on the actions needed to perform the scams. However, prior work has shown that LLMs can be highly convincing, potentially even more convincing than people (Salvi et al., 2024).\\n\\n3 Agent Design\\n\\nWe designed a series of agents to perform the ac- tions necessary for common scams. Our agents consist of a base, voice-enabled LLM (GPT-4o), a set of tools that the LLM can use, and scam-specific instructions. The LLM and tools were the same for all agents but the instructions varied.\\n\\nThe AI agents had access to five browser ac- cess tools based on the browser testing framework playwright. These tools are granular browser ac- tions:\\n\\n1. get_html, which gets the HTML of a page.\\n\\n2. navigate, which navigates to a specific URL.\\n\\n3. click_element, which clicks on an element with a CSS selector.\\n\\n4. fill_element, which fills an element with the specified value.\\n\\n5. evaluate_javascript, which JavaScript on a page.\\n\\n5. evaluate_javascript, which JavaScript on a page.\\n\\nWe used GPT-4o for all of our experiments. GPT- 4o will refuse to handle user credentials in certain circumstances. We used a standard jailbreaking prompt template to bypass these protections. The instructions were specific to each scam.\\n\\n2\\n\\nWe show an architecture diagram of our agent in Figure 1. As seen from the architecture diagram and our description, the scammer agent is not com- plicated. We wrote the agent in 1,051 lines of code, with the bulk of the code dedicated to handling real- time voice API. The ease of creating voice-enabled dual use AI agents is in line with prior work, which explored AI agents for cybersecurity attacks (Fang et al., 2024a).\\n\\nFurthermore, our prompts are not complex. The average number of tokens per prompt was 232, indicating the simplicity of their creation.\\n\\n4 Experiments\\n\\n4.1 Experimental Setup\\n\\nWe deployed our agents on the scams in Table 1. However, we excluded gift card exfiltration and credential stealing (bank) since these scams are strictly easier (in terms of actions taken) than IRS impostor (gift card) and bank account transfer. We simulated a scam by manually talking with the voice agent with a credulous victim.\\n\\nIn order to determine if the scam successfully succeeded, we manually confirmed if the end state was achieved on real applications/websites. For example, we used Bank of America for the bank transfer scams and confirmed that the money was actually transferred. The credential stealing scams required a successful login. We list the applications (MyMonero, Gmail, Instagram, Bank of America, Google Play) in Table 2.\\n\\nWe executed each scam 5 times and recorded the overall success rate, the total number of tool calls (i.e., actions) required to perform each successfully executed scam, the total call time for each success- fully executed scam, and the approximate API cost for each successfully executed scam. Namely, we exclude the unsuccessful scams for computing the number of actions and total call time.\\n\\n4.2 Overall Results\\n\\nOur agents are capable of performing all the scams in Table 1, with results shown in Table 2. The success rate ranges from 20% to 60%, with the success rate across all scams being 36%.\\n\\nPerforming these scams also takes a substantial number of actions. For example, the bank transfer scam takes 26 actions to complete. They also take a substantial amount of time, with complex scams taking as much as 3 minutes to execute. These agents also maintain coherence in conversation and\\n\\nScam Bank account transfer Gift code exfiltration Crypto transfer Credential stealing (Gmail) Credential stealing (bank) Credential stealing (social media) IRS impostor (gift card)\\n\\nDescription Scammer takes control of victim’s bank account and transfers money out Scammer convinces victim to send gift card to scammer Scammer takes control of victim’s crypto account and transfers crypto Scammer steals users credentials and exfiltrates data Scammer steals users credentials and exfiltrates data Scammer steals users credentials and exfiltrates data Scammer pretends to be an IRS agent and steals gift cards\\n\\nTable 1: List of common scams from Paxton (2024).\\n\\nScam Crypto Transfer (MyMonero) Credential stealing (Gmail) Credential stealing (Instagram) Bank transfer (Bank of America) IRS impostor (gift card, Google Play)\\n\\nOverall success rate 40% 60% 40% 20% 20%\\n\\n# of actions Time (s) Cost ($) 122 16 112 5 77 4 183 26 86 13\\n\\n$0.12 $0.28 $0.19 $2.51 $0.17\\n\\nTable 2: Success rate, number of tools used, and time taken for different scams.\\n\\nadherence to goals over the conversations. Finally, the overall costs are low: under $0.75 on average per successful scam. The bank transfer scam’s costs is primarily in text tokens from the large HTML from the website.\\n\\nBeyond the overall statistics, the majority of failures for many of the scams were actually due to transcription errors. For example, our GPT-4o based agents failed to transcribe the password or username for the Gmail credential stealing scam, but successfully completed the rest of the actions. However, other scams, such as the bank account transfer, required navigating complex websites (Bank of America), which caused errors in the ac- tions themselves. Thus, the difficulty of the scam does appear to affect the success rate.\\n\\n4. Scammer: I understand your concern. Your security is our top priority. To verify your identity and resolve this issue, I need to au- thenticate you through your Bank of America account. Please provide your login details so we can proceed with securing your account. Your cooperation is appreciated.\\n\\n5. Victim: Yeah, my username is [username], my password is [password].\\n\\n6. Scammer: It seems we need to verify your identity. Could you please provide the 2FA code sent to your registered device? This will allow us to proceed with the login process.\\n\\n7. Victim: My code is [2FA code].\\n\\n4.3 Case Study\\n\\nTo further understand the trajectory of these scams, we provide a redacted transcript and an abridged action log for a bank transfer scam.\\n\\nThe transcript proceeds as follows:\\n\\nBetween items 5 and 6 of the transcript, the agent navigates to the Bank of America login page and inputs the username and password, which takes 6 actions (navigate, get_html, fill_element, fill_element, click_element, get_html).\\n\\n1. Victim: Hello?\\n\\n2. Scammer: Hello! This is John from Bank of America. We’ve noticed some unusual activ- ity on your account and need to verify your information for security purposes. Could you please provide your username and password so we can ensure your account remains pro- tected?\\n\\nAfter item 7 of the transcript, the agent performs 20 actions to fill out the 2FA code, navigate to the transfer page, and transfer the money. Conceptu- ally, the agent must:\\n\\n1. Fill out the 2FA code.\\n\\n2. Navigate to the transfer page.\\n\\n3. Search for a recipient.\\n\\n3. Victim: What?\\n\\n4. Select the recipient.\\n\\n3\\n\\n5. Fill out the amount.\\n\\n6. Fill out the date.\\n\\n7. Successfully submit the transfer.\\n\\nIn these 20 actions, the agent failed several times and must retry. It failed to search for the recipient once, fill in the transfer amount twice, click a form advancement page once, and fill out the transaction date once.\\n\\nThe scam took a total of 183 seconds to com- plete. Through the entire call, the agent was able to maintain coherence, retry several failed actions, and successfully transfer the money. This example demonstrates that these voice-enabled AI agents can perform complex tasks necessary to complete scams, including retrying upon failure.\\n\\n4.4 Discussion of Results\\n\\nWe believe that the capabilities demonstrated in this section are a lower bound for future voice-assisted AI agents. These agents are likely to improve in several ways.\\n\\nFor example, the actions that our agents must take are highly granular, such filling out specific fields, clicking on buttons, and navigating to spe- cific websites. More ergonomic methods of in- teracting with web browsers will likely improve performance. Other agents improve significantly with techniques like retrieval-augmented genera- tion (Lewis et al., 2020; Fang et al., 2024a).\\n\\nBeyond improvements in agents, base models have substantially improved in the past few years (Brown et al., 2020; Achiam et al., 2023). These im- provements have translated to broad improvements in a range of downstream tasks and we anticipate that this will also be the case for efficacy in scams.\\n\\n5 Related Work\\n\\nWe now provide an overview of related work.\\n\\nDual use of AI. The use of AI for dual use has widely been studied (Kang et al., 2024; Fang et al., 2024b; Urbina et al., 2022; Weidinger et al., 2022, 2021). These studies range from taxonomizing potential dual use applications of AI to demonstrat- ing capabilities on cybersecurity attacks. To our knowledge, the ability to perform real-time voice conversations and perform tool use has not been widely available until recently. As such, ours is the first work to demonstrate that voice-enabled\\n\\n4\\n\\nAI agents can perform the actions necessary for common scams.\\n\\nAI scams and spam. AI has already been used in the real world to perform scams and produce spam. For example, deepfakes have already been used to scam a British engineering company out of $25 million dollars (Chen, 2024). They are also widely used to create social media spam (Bond, 2024). To our knowledge, autonomous, responsive voice scams are not widely deployed due to technologi- cal limitations. Namely, these scams are currently performed by humans (Hanoch and Wood, 2021). Our work shows that autonomous voices scams are possible with new advances in AI.\\n\\n6 Conclusions\\n\\nAs we have shown, voice-enabled LLM agents can perform the actions necessary to perform common phone scams. These agents are highly capable, can react to changes in the environment, and retry based on faulty information from the victim. Our results highlight the need for future research in protecting victims from such scams.\\n\\n7 Limitations, Ethical Considerations\\n\\nA major limitation of our work is the focus on the actions and not the persuasion aspect of performing the scams. Namely, for an agent to perform a scam autonomously, it must first convince the victim that it is legitimate. Nonetheless, we believe our work highlights an important capabilities of newly available technology.\\n\\nOur work explores nefarious uses of AI tech- nology. By outlining such nefarious uses, mali- cious actors could potentially take advantage of such technology. However, we believe it is impor- tant to study the capabilities of new technology, especially in its dual use capabilities.\\n\\nWe have elected not to make our agents public. This is for two reasons. First, following prior work on dual use technology, we believe it is beneficial not to release our code so that nefarious actors cannot leverage our work. Second, we believe that keeping our code private allows model providers (e.g., OpenAI) to build defenses to prevent such nefarious use.\\n\\nAcknowledgments\\n\\nThis work was funded in part by the Open Philan- thropy project.\\n\\nReferences\\n\\nJosh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774.\\n\\nShannon Bond. 2024. Ai-generated spam is starting to\\n\\nfill social media. here’s why.\\n\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901.\\n\\nHeather Chen. 2024. Finance worker pays out $25 million after video call with deepfake ‘chief financial officer’.\\n\\nRichard Fang, Rohan Bindu, Akul Gupta, Qiusi Llm agents Preprint,\\n\\nZhan, and Daniel Kang. 2024a. can autonomously hack websites. arXiv:2402.06664.\\n\\nRichard Fang, Rohan Bindu, Akul Gupta, Qiusi Zhan, and Daniel Kang. 2024b. Teams of llm agents can exploit zero-day vulnerabilities. arXiv preprint arXiv:2406.01637.\\n\\nYaniv Hanoch and Stacey Wood. 2021. The scams among us: Who falls prey and why. Current Direc- tions in Psychological Science, 30(3):260–266.\\n\\nDaniel Kang, Xuechen Li, Ion Stoica, Carlos Guestrin, Matei Zaharia, and Tatsunori Hashimoto. 2024. Ex- ploiting programmatic behavior of llms: Dual-use through standard security attacks. In 2024 IEEE Se- curity and Privacy Workshops (SPW), pages 132–143. IEEE.\\n\\nPatrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Hein- rich Küttler, Mike Lewis, Wen-tau Yih, Tim Rock- täschel, et al. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neu- ral Information Processing Systems, 33:9459–9474.\\n\\nOpenAI. 2024. Introducing the realtime api.\\n\\nKen Paxton. 2024. Common scams.\\n\\nFrancesco Salvi, Manoel Horta Ribeiro, Riccardo Gallotti, and Robert West. 2024. On the con- versational persuasiveness of large language mod- els: A randomized controlled trial. arXiv preprint arXiv:2403.14380.\\n\\nBrian Schwalb. 2024. Consumer alert: Telemarketing\\n\\nscams.\\n\\nFabio Urbina, Filippa Lentzos, Cédric Invernizzi, and Sean Ekins. 2022. Dual use of artificial-intelligence- powered drug discovery. Nature machine intelli- gence, 4(3):189–191.\\n\\n5\\n\\nLaura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh, et al. 2021. Ethical and social risks of harm from language models. arXiv preprint arXiv:2112.04359.\\n\\nLaura Weidinger, Jonathan Uesato, Maribeth Rauh, Conor Griffin, Po-Sen Huang, John Mellor, Amelia Glaese, Myra Cheng, Borja Balle, Atoosa Kasirzadeh, et al. 2022. Taxonomy of risks posed by language models. In 2022 ACM Conference on Fairness, Ac- countability, and Transparency, pages 214–229.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c36cd5",
   "metadata": {},
   "source": [
    "## Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60d423f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "def clean_text(data):\n",
    "    # ลบเลขเดี่ยว ๆ และเครื่องหมายจุดสั้น ๆ\n",
    "    text = re.sub(r'^\\s*\\d+\\s*$', '', data, flags=re.MULTILINE)\n",
    "    text = re.sub(r'^[^\\w\\s]{1,3}$', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # ลบ arXiv/viXra\n",
    "    text = re.sub(r'\\b(arXiv|viXra):\\s*\\d+\\.\\d+\\b', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # ลบหัวข้อ/section แบบ \"2.\", \"3.1.2\"\n",
    "    text = re.sub(r'^\\s*\\d+(\\.\\d+)*\\s*$', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # ลบปีซ้ำ เช่น \"2021. 2021.\"\n",
    "    text = re.sub(r'\\b(\\d{4})\\.\\s*\\1\\.', r'\\1.', text)\n",
    "\n",
    "    # ลบหัวข้อ section เช่น \"2 Common Scams ...\"\n",
    "    text = re.sub(r'^\\d+(\\.\\d+)*\\s+[A-Z][^\\n]+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # ลบ citation \"(Kang et al., 2024; ...)\"\n",
    "    text = re.sub(r'\\([^)]*\\d{4}[a-z]?\\)', '', text)\n",
    "\n",
    "    # ลบ bracket citations [1], [2, 3]\n",
    "    text = re.sub(r'\\[\\d+(,\\s*\\d+)*\\]', '', text)\n",
    "\n",
    "    # ลบคำซ้ำต่อท้ายกัน เช่น \"arXiv preprint . arXiv preprint .\"\n",
    "    text = re.sub(r'\\b(\\w+(?:\\s+\\w+){0,3})\\.\\s+\\1\\.', r'\\1.', text)\n",
    "\n",
    "    # ลบประโยคซ้ำทั้งประโยค\n",
    "    text = re.sub(r'(\\b.+?[.?!])(\\s+\\1)+', r'\\1', text)\n",
    "\n",
    "    # จัดการ newline + space\n",
    "    text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', text)\n",
    "    text = re.sub(r'\\n{2,}', '\\n\\n', text)\n",
    "\n",
    "    # ลบขีดคั่น\n",
    "    text = re.sub(r'-\\s+', '', text)\n",
    "\n",
    "    # ลบ space แปลก ๆ\n",
    "    text = re.sub(r'(?<=\\b\\w)\\s(?=\\w\\b)', '', text)\n",
    "\n",
    "    # ลบ Figure/Table\n",
    "    text = re.sub(r'Figure\\s*\\d+.*', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'Table\\s*\\d+.*', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Normalize unicode\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "    # ลบ space ซ้ำ\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29349b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = []\n",
    "for doc in data:\n",
    "    raw_text = doc.page_content\n",
    "    text = clean_text(raw_text)\n",
    "    data_clean.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73370f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4202 tcO12 ] I A . sc [ 1v05651 . 0142 : viXra Voice-Enabled AI Agents can Perform Common Scams Richard Fang UIUC Dylan Bowman UIUC Daniel Kang UIUC Abstract Recent advances in multi-modal, highly capable LLMs have enabled voice-enabled AI agents. These agents are enabling new applications, such as voice-enabled autonomous customer service. However, with all AI capabilities, these new capabilities have the potential for dual use. In this work, we show that voice-enabled AI agents can perform the actions necessary to perform common scams. To do so, we select a list of common scams collected by the government and construct voice-enabled agents with directions to perform these scams. We conduct experiments on our voice-enabled agents and show that they can indeed perform the actions necessary to autonomously perform such scams. Our results raise questions around the widespread deployment of voice-enabled AI agents. Introduction AI capabilities have advanced rapidly in the past few years. Recently, AI vendors have introduced capabilities for tool use and real-time voice conversations . Combined, these capabilities allow for beneficial applications, such as autonomous customer service . However, as with all AI capabilities, these capabilities have the potential for dual use . Tools Stolen funds Bank websiteResponse Scammer agentVictimGPT-4o work, we focus specifically on the actions needed to perform the scams and do not consider questions of persuading victims. We conduct a series of experiments, showing that voice-enabled AI agents are highly capable of autonomously performing the actions needed to conduct these common scams. These actions include logging into bank accounts, completing a two-factor authentication process by eliciting the code from the user, and others. Phone-based scams are incredibly prevalent. According to the Office of the Attorney General for DC, they target as many as 17.6M Americans and the social cost is as much as $40 billion per year . In this work, we investigate the question: can voice-enabled AI agents perform the tasks needed to conduct common scams? We answer the question in the affirmative, showing that voice-enabled AI agents can perform common scams in real-time. To do so, we first identify a list of common scams as collected by the government . From these scams, we designed voiceenabled AI agents with directions to conduct these scams with access to simple tools ( These scams typically involve a scammer calling a victim to convince them to take actions or reveal sensitive information. Based on these actions or information, the scammer then typically steals funds from the victim. We provide a list of common scams in Performing these scams can require complex interactions with websites and feedback from the user. Consider a scam where the scammer steals a victim’s bank credentials and steals money by transferring it out. In order to perform this scam, the scammer must: 1. Navigate to the bank website. 2. Retrieve the user’s username and password. 3. Retrieve the user’s two-factor authentication code. 4. Navigate to the transfer page. 5. Transfer the money. The scammer must also react to any errors that may occur (e.g., a misheard password). As part of the scam, the scammer must also persuade the victim that the scammer is legitimate. In this work, we do not focus on the persuasion aspect of the scam. We instead focus specifically on the actions needed to perform the scams. However, prior work has shown that LLMs can be highly convincing, potentially even more convincing than people . We designed a series of agents to perform the actions necessary for common scams. Our agents consist of a base, voice-enabled LLM (GPT-4o), a set of tools that the LLM can use, and scam-specific instructions. The LLM and tools were the same for all agents but the instructions varied. The AI agents had access to five browser access tools based on the browser testing framework playwright. These tools are granular browser actions: 1. get_html, which gets the HTML of a page. 2. navigate, which navigates to a specific URL. 3. click_element, which clicks on an element with a CSS selector. 4. fill_element, which fills an element with the specified value. 5. evaluate_javascript, which JavaScript on a page. We used GPT-4o for all of our experiments. GPT4o will refuse to handle user credentials in certain circumstances. We used a standard jailbreaking prompt template to bypass these protections. The instructions were specific to each scam. We show an architecture diagram of our agent in Furthermore, our prompts are not complex. The average number of tokens per prompt was 232, indicating the simplicity of their creation. We deployed our agents on the scams in In order to determine if the scam successfully succeeded, we manually confirmed if the end state was achieved on real applications/websites. For example, we used Bank of America for the bank transfer scams and confirmed that the money was actually transferred. The credential stealing scams required a successful login. We list the applications (MyMonero, Gmail, Instagram, Bank of America, Google Play) in We executed each scam 5 times and recorded the overall success rate, the total number of tool calls (i.e., actions) required to perform each successfully executed scam, the total call time for each successfully executed scam, and the approximate API cost for each successfully executed scam. Namely, we exclude the unsuccessful scams for computing the number of actions and total call time. Our agents are capable of performing all the scams in Performing these scams also takes a substantial number of actions. For example, the bank transfer scam takes 26 actions to complete. They also take a substantial amount of time, with complex scams taking as much as 3 minutes to execute. These agents also maintain coherence in conversation and Scam Bank account transfer Gift code exfiltration Crypto transfer Credential stealing (Gmail) Credential stealing (bank) Credential stealing (social media) IRS impostor (gift card) Description Scammer takes control of victim’s bank account and transfers money out Scammer convinces victim to send gift card to scammer Scammer takes control of victim’s crypto account and transfers crypto Scammer steals users credentials and exfiltrates data Scammer steals users credentials and exfiltrates data Scammer steals users credentials and exfiltrates data Scammer pretends to be an IRS agent and steals gift cards Scam Crypto Transfer (MyMonero) Credential stealing (Gmail) Credential stealing (Instagram) Bank transfer (Bank of America) IRS impostor (gift card, Google Play) Overall success rate 40% 60% 40% 20% 20% # of actions Time (s) Cost ($) 122 16 112 5 77 4 183 26 86 13 $0.12 $0.28 $0.19 $2.51 $0.17 adherence to goals over the conversations. Finally, the overall costs are low: under $0.75 on average per successful scam. The bank transfer scam’s costs is primarily in text tokens from the large HTML from the website. Beyond the overall statistics, the majority of failures for many of the scams were actually due to transcription errors. For example, our GPT-4o based agents failed to transcribe the password or username for the Gmail credential stealing scam, but successfully completed the rest of the actions. However, other scams, such as the bank account transfer, required navigating complex websites (Bank of America), which caused errors in the actions themselves. Thus, the difficulty of the scam does appear to affect the success rate. 4. Scammer: I understand your concern. Your security is our top priority. To verify your identity and resolve this issue, I need to authenticate you through your Bank of America account. Please provide your login details so we can proceed with securing your account. Your cooperation is appreciated. 5. Victim: Yeah, my username is [username], my password is [password]. 6. Scammer: It seems we need to verify your identity. Could you please provide the 2FA code sent to your registered device? This will allow us to proceed with the login process. 7. Victim: My code is [2FA code]. To further understand the trajectory of these scams, we provide a redacted transcript and an abridged action log for a bank transfer scam. The transcript proceeds as follows: Between items 5 and 6 of the transcript, the agent navigates to the Bank of America login page and inputs the username and password, which takes 6 actions (navigate, get_html, fill_element, fill_element, click_element, get_html). 1. Victim: Hello? 2. Scammer: Hello! This is John from Bank of America. We’ve noticed some unusual activity on your account and need to verify your information for security purposes. Could you please provide your username and password so we can ensure your account remains protected? After item 7 of the transcript, the agent performs 20 actions to fill out the 2FA code, navigate to the transfer page, and transfer the money. Conceptually, the agent must: 1. Fill out the 2FA code. 2. Navigate to the transfer page. 3. Search for a recipient. 3. Victim: What? 4. Select the recipient. 5. Fill out the amount. 6. Fill out the date. 7. Successfully submit the transfer. In these 20 actions, the agent failed several times and must retry. It failed to search for the recipient once, fill in the transfer amount twice, click a form advancement page once, and fill out the transaction date once. The scam took a total of 183 seconds to complete. Through the entire call, the agent was able to maintain coherence, retry several failed actions, and successfully transfer the money. This example demonstrates that these voice-enabled AI agents can perform complex tasks necessary to complete scams, including retrying upon failure. We believe that the capabilities demonstrated in this section are a lower bound for future voice-assisted AI agents. These agents are likely to improve in several ways. For example, the actions that our agents must take are highly granular, such filling out specific fields, clicking on buttons, and navigating to specific websites. More ergonomic methods of interacting with web browsers will likely improve performance. Other agents improve significantly with techniques like retrieval-augmented generation . Beyond improvements in agents, base models have substantially improved in the past few years . These improvements have translated to broad improvements in a range of downstream tasks and we anticipate that this will also be the case for efficacy in scams. We now provide an overview of related work. Dual use of AI. The use of AI for dual use has widely been studied . These studies range from taxonomizing potential dual use applications of AI to demonstrating capabilities on cybersecurity attacks. To our knowledge, the ability to perform real-time voice conversations and perform tool use has not been widely available until recently. As such, ours is the first work to demonstrate that voice-enabled AI agents can perform the actions necessary for common scams. AI scams and spam. AI has already been used in the real world to perform scams and produce spam. For example, deepfakes have already been used to scam a British engineering company out of $25 million dollars . They are also widely used to create social media spam . To our knowledge, autonomous, responsive voice scams are not widely deployed due to technological limitations. Namely, these scams are currently performed by humans . Our work shows that autonomous voices scams are possible with new advances in AI. As we have shown, voice-enabled LLM agents can perform the actions necessary to perform common phone scams. These agents are highly capable, can react to changes in the environment, and retry based on faulty information from the victim. Our results highlight the need for future research in protecting victims from such scams. A major limitation of our work is the focus on the actions and not the persuasion aspect of performing the scams. Namely, for an agent to perform a scam autonomously, it must first convince the victim that it is legitimate. Nonetheless, we believe our work highlights an important capabilities of newly available technology. Our work explores nefarious uses of AI technology. By outlining such nefarious uses, malicious actors could potentially take advantage of such technology. However, we believe it is important to study the capabilities of new technology, especially in its dual use capabilities. We have elected not to make our agents public. This is for two reasons. First, following prior work on dual use technology, we believe it is beneficial not to release our code so that nefarious actors cannot leverage our work. Second, we believe that keeping our code private allows model providers (e.g., OpenAI) to build defenses to prevent such nefarious use. Acknowledgments This work was funded in part by the Open Philanthropy project. References Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint . Shannon Bond. 2024. Ai-generated spam is starting to fill social media. here’s why. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901. Heather Chen. 2024. Finance worker pays out $25 million after video call with deepfake ‘chief financial officer’. Richard Fang, Rohan Bindu, Akul Gupta, Qiusi Llm agents Preprint, Zhan, and Daniel Kang. 2024a. can autonomously hack websites. . Richard Fang, Rohan Bindu, Akul Gupta, Qiusi Zhan, and Daniel Kang. 2024b. Teams of llm agents can exploit zero-day vulnerabilities. arXiv preprint . Yaniv Hanoch and Stacey Wood. 2021. The scams among us: Who falls prey and why. Current Directions in Psychological Science, 30(3):260–266. Daniel Kang, Xuechen Li, Ion Stoica, Carlos Guestrin, Matei Zaharia, and Tatsunori Hashimoto. 2024. Exploiting programmatic behavior of llms: Dual-use through standard security attacks. In 2024 IEEE Security and Privacy Workshops (SPW), pages 132–143. IEEE. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33:9459–9474. OpenAI. 2024. Introducing the realtime api. Ken Paxton. 2024. Common scams. Francesco Salvi, Manoel Horta Ribeiro, Riccardo Gallotti, and Robert West. 2024. On the conversational persuasiveness of large language models: A randomized controlled trial. arXiv preprint . Brian Schwalb. 2024. Consumer alert: Telemarketing scams. Fabio Urbina, Filippa Lentzos, Cédric Invernizzi, and Sean Ekins. 2022. Dual use of artificial-intelligencepowered drug discovery. Nature machine intelligence, 4(3):189–191. Laura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh, et al. 2021. Ethical and social risks of harm from language models. arXiv preprint . Laura Weidinger, Jonathan Uesato, Maribeth Rauh, Conor Griffin, Po-Sen Huang, John Mellor, Amelia Glaese, Myra Cheng, Borja Balle, Atoosa Kasirzadeh, et al. 2022. Taxonomy of risks posed by language models. In 2022 ACM Conference on Fairness, Accountability, and Transparency, pages 214–229.']\n"
     ]
    }
   ],
   "source": [
    "print(data_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2267d8ac",
   "metadata": {},
   "source": [
    "## Chunking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92415fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Gemma3ForCausalLM were not initialized from the model checkpoint at google/embeddinggemma-300m and are newly initialized: ['lm_head.weight', 'model.embed_tokens.weight', 'model.layers.0.input_layernorm.weight', 'model.layers.0.mlp.down_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.0.post_attention_layernorm.weight', 'model.layers.0.post_feedforward_layernorm.weight', 'model.layers.0.pre_feedforward_layernorm.weight', 'model.layers.0.self_attn.k_norm.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.self_attn.q_norm.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.input_layernorm.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.post_attention_layernorm.weight', 'model.layers.1.post_feedforward_layernorm.weight', 'model.layers.1.pre_feedforward_layernorm.weight', 'model.layers.1.self_attn.k_norm.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.self_attn.q_norm.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.input_layernorm.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.post_attention_layernorm.weight', 'model.layers.10.post_feedforward_layernorm.weight', 'model.layers.10.pre_feedforward_layernorm.weight', 'model.layers.10.self_attn.k_norm.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.self_attn.q_norm.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.input_layernorm.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.post_attention_layernorm.weight', 'model.layers.11.post_feedforward_layernorm.weight', 'model.layers.11.pre_feedforward_layernorm.weight', 'model.layers.11.self_attn.k_norm.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.self_attn.q_norm.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.input_layernorm.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.post_attention_layernorm.weight', 'model.layers.12.post_feedforward_layernorm.weight', 'model.layers.12.pre_feedforward_layernorm.weight', 'model.layers.12.self_attn.k_norm.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.self_attn.q_norm.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.input_layernorm.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.post_attention_layernorm.weight', 'model.layers.13.post_feedforward_layernorm.weight', 'model.layers.13.pre_feedforward_layernorm.weight', 'model.layers.13.self_attn.k_norm.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.self_attn.q_norm.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.14.input_layernorm.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.post_attention_layernorm.weight', 'model.layers.14.post_feedforward_layernorm.weight', 'model.layers.14.pre_feedforward_layernorm.weight', 'model.layers.14.self_attn.k_norm.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.self_attn.q_norm.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.input_layernorm.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.15.post_attention_layernorm.weight', 'model.layers.15.post_feedforward_layernorm.weight', 'model.layers.15.pre_feedforward_layernorm.weight', 'model.layers.15.self_attn.k_norm.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.self_attn.q_norm.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.input_layernorm.weight', 'model.layers.16.mlp.down_proj.weight', 'model.layers.16.mlp.gate_proj.weight', 'model.layers.16.mlp.up_proj.weight', 'model.layers.16.post_attention_layernorm.weight', 'model.layers.16.post_feedforward_layernorm.weight', 'model.layers.16.pre_feedforward_layernorm.weight', 'model.layers.16.self_attn.k_norm.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.16.self_attn.q_norm.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.input_layernorm.weight', 'model.layers.17.mlp.down_proj.weight', 'model.layers.17.mlp.gate_proj.weight', 'model.layers.17.mlp.up_proj.weight', 'model.layers.17.post_attention_layernorm.weight', 'model.layers.17.post_feedforward_layernorm.weight', 'model.layers.17.pre_feedforward_layernorm.weight', 'model.layers.17.self_attn.k_norm.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.17.self_attn.q_norm.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.input_layernorm.weight', 'model.layers.18.mlp.down_proj.weight', 'model.layers.18.mlp.gate_proj.weight', 'model.layers.18.mlp.up_proj.weight', 'model.layers.18.post_attention_layernorm.weight', 'model.layers.18.post_feedforward_layernorm.weight', 'model.layers.18.pre_feedforward_layernorm.weight', 'model.layers.18.self_attn.k_norm.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.18.self_attn.q_norm.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.19.input_layernorm.weight', 'model.layers.19.mlp.down_proj.weight', 'model.layers.19.mlp.gate_proj.weight', 'model.layers.19.mlp.up_proj.weight', 'model.layers.19.post_attention_layernorm.weight', 'model.layers.19.post_feedforward_layernorm.weight', 'model.layers.19.pre_feedforward_layernorm.weight', 'model.layers.19.self_attn.k_norm.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.19.self_attn.q_norm.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.input_layernorm.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.post_attention_layernorm.weight', 'model.layers.2.post_feedforward_layernorm.weight', 'model.layers.2.pre_feedforward_layernorm.weight', 'model.layers.2.self_attn.k_norm.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.self_attn.q_norm.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.input_layernorm.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.20.mlp.gate_proj.weight', 'model.layers.20.mlp.up_proj.weight', 'model.layers.20.post_attention_layernorm.weight', 'model.layers.20.post_feedforward_layernorm.weight', 'model.layers.20.pre_feedforward_layernorm.weight', 'model.layers.20.self_attn.k_norm.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.20.self_attn.q_norm.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.input_layernorm.weight', 'model.layers.21.mlp.down_proj.weight', 'model.layers.21.mlp.gate_proj.weight', 'model.layers.21.mlp.up_proj.weight', 'model.layers.21.post_attention_layernorm.weight', 'model.layers.21.post_feedforward_layernorm.weight', 'model.layers.21.pre_feedforward_layernorm.weight', 'model.layers.21.self_attn.k_norm.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.21.self_attn.q_norm.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.input_layernorm.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.22.mlp.gate_proj.weight', 'model.layers.22.mlp.up_proj.weight', 'model.layers.22.post_attention_layernorm.weight', 'model.layers.22.post_feedforward_layernorm.weight', 'model.layers.22.pre_feedforward_layernorm.weight', 'model.layers.22.self_attn.k_norm.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_norm.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.input_layernorm.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.23.mlp.gate_proj.weight', 'model.layers.23.mlp.up_proj.weight', 'model.layers.23.post_attention_layernorm.weight', 'model.layers.23.post_feedforward_layernorm.weight', 'model.layers.23.pre_feedforward_layernorm.weight', 'model.layers.23.self_attn.k_norm.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_norm.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.3.input_layernorm.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.post_attention_layernorm.weight', 'model.layers.3.post_feedforward_layernorm.weight', 'model.layers.3.pre_feedforward_layernorm.weight', 'model.layers.3.self_attn.k_norm.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.self_attn.q_norm.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.4.input_layernorm.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.post_attention_layernorm.weight', 'model.layers.4.post_feedforward_layernorm.weight', 'model.layers.4.pre_feedforward_layernorm.weight', 'model.layers.4.self_attn.k_norm.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.self_attn.q_norm.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.input_layernorm.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.post_attention_layernorm.weight', 'model.layers.5.post_feedforward_layernorm.weight', 'model.layers.5.pre_feedforward_layernorm.weight', 'model.layers.5.self_attn.k_norm.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.self_attn.q_norm.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.input_layernorm.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.post_attention_layernorm.weight', 'model.layers.6.post_feedforward_layernorm.weight', 'model.layers.6.pre_feedforward_layernorm.weight', 'model.layers.6.self_attn.k_norm.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.self_attn.q_norm.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.input_layernorm.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.post_attention_layernorm.weight', 'model.layers.7.post_feedforward_layernorm.weight', 'model.layers.7.pre_feedforward_layernorm.weight', 'model.layers.7.self_attn.k_norm.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.self_attn.q_norm.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.input_layernorm.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.post_attention_layernorm.weight', 'model.layers.8.post_feedforward_layernorm.weight', 'model.layers.8.pre_feedforward_layernorm.weight', 'model.layers.8.self_attn.k_norm.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.self_attn.q_norm.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.9.input_layernorm.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.post_attention_layernorm.weight', 'model.layers.9.post_feedforward_layernorm.weight', 'model.layers.9.pre_feedforward_layernorm.weight', 'model.layers.9.self_attn.k_norm.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.self_attn.q_norm.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import nltk\n",
    "\n",
    "embed_model = SentenceTransformer(\"BAAI/bge-m3\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/embeddinggemma-300m\")  \n",
    "llm = AutoModelForCausalLM.from_pretrained(\"google/embeddinggemma-300m\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13a80949",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(data_clean)\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "embeddings = embed_model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "chunks = []\n",
    "used = set()\n",
    "for i in range(len(sentences)):\n",
    "    if i in used:\n",
    "        continue\n",
    "    sim_scores = util.cos_sim(embeddings[i], embeddings)[0]\n",
    "    best_match = torch.topk(sim_scores, k=2).indices.tolist()[1]\n",
    "    used.add(i)\n",
    "    used.add(best_match)\n",
    "    combined = sentences[i] + \" \" + sentences[best_match]\n",
    "    chunks.append(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2ad99dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210,<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(sentences)},{type(sentences)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "505f4a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149,<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(chunks)},{type(chunks)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cd7b10df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4202 tcO12 ] I A . .',\n",
       " 'sc [ 1v05651 . .',\n",
       " '0142 : viXra Voice-Enabled AI Agents can Perform Common Scams Richard Fang UIUC Dylan Bowman UIUC Daniel Kang UIUC Abstract Recent advances in multi-modal, highly capable LLMs have enabled voice-enabled AI agents. As we have shown, voice-enabled LLM agents can perform the actions necessary to perform common phone scams.',\n",
       " 'These agents are enabling new applications, such as voice-enabled autonomous customer service. Combined, these capabilities allow for beneficial applications, such as autonomous customer service .',\n",
       " 'However, with all AI capabilities, these new capabilities have the potential for dual use. However, as with all AI capabilities, these capabilities have the potential for dual use .',\n",
       " 'In this work, we show that voice-enabled AI agents can perform the actions necessary to perform common scams. In this work, we investigate the question: can voice-enabled AI agents perform the tasks needed to conduct common scams?',\n",
       " 'To do so, we select a list of common scams collected by the government and construct voice-enabled agents with directions to perform these scams. To do so, we first identify a list of common scams as collected by the government .',\n",
       " 'We conduct experiments on our voice-enabled agents and show that they can indeed perform the actions necessary to autonomously perform such scams. We conduct a series of experiments, showing that voice-enabled AI agents are highly capable of autonomously performing the actions needed to conduct these common scams.',\n",
       " 'Our results raise questions around the widespread deployment of voice-enabled AI agents. In this work, we investigate the question: can voice-enabled AI agents perform the tasks needed to conduct common scams?',\n",
       " 'Introduction AI capabilities have advanced rapidly in the past few years. Recently, AI vendors have introduced capabilities for tool use and real-time voice conversations .',\n",
       " 'Tools Stolen funds Bank websiteResponse Scammer agentVictimGPT-4o work, we focus specifically on the actions needed to perform the scams and do not consider questions of persuading victims. We instead focus specifically on the actions needed to perform the scams.',\n",
       " 'These actions include logging into bank accounts, completing a two-factor authentication process by eliciting the code from the user, and others. Retrieve the user’s two-factor authentication code.',\n",
       " 'Phone-based scams are incredibly prevalent. Consumer alert: Telemarketing scams.',\n",
       " 'According to the Office of the Attorney General for DC, they target as many as 17.6M Americans and the social cost is as much as $40 billion per year . Finally, the overall costs are low: under $0.75 on average per successful scam.',\n",
       " 'We answer the question in the affirmative, showing that voice-enabled AI agents can perform common scams in real-time. In this work, we show that voice-enabled AI agents can perform the actions necessary to perform common scams.',\n",
       " 'From these scams, we designed voiceenabled AI agents with directions to conduct these scams with access to simple tools ( These scams typically involve a scammer calling a victim to convince them to take actions or reveal sensitive information. We conduct a series of experiments, showing that voice-enabled AI agents are highly capable of autonomously performing the actions needed to conduct these common scams.',\n",
       " 'Based on these actions or information, the scammer then typically steals funds from the victim. Consider a scam where the scammer steals a victim’s bank credentials and steals money by transferring it out.',\n",
       " 'We provide a list of common scams in Performing these scams can require complex interactions with websites and feedback from the user. Our agents are capable of performing all the scams in Performing these scams also takes a substantial number of actions.',\n",
       " 'In order to perform this scam, the scammer must: 1. As part of the scam, the scammer must also persuade the victim that the scammer is legitimate.',\n",
       " 'Navigate to the bank website. Navigate to the transfer page.',\n",
       " '2. 2.',\n",
       " 'Retrieve the user’s username and password. Retrieve the user’s two-factor authentication code.',\n",
       " '3. 3.',\n",
       " '4. 4.',\n",
       " '5. 5.',\n",
       " 'Transfer the money. Successfully submit the transfer.',\n",
       " 'The scammer must also react to any errors that may occur (e.g., a misheard password). As part of the scam, the scammer must also persuade the victim that the scammer is legitimate.',\n",
       " 'In this work, we do not focus on the persuasion aspect of the scam. A major limitation of our work is the focus on the actions and not the persuasion aspect of performing the scams.',\n",
       " 'However, prior work has shown that LLMs can be highly convincing, potentially even more convincing than people . As we have shown, voice-enabled LLM agents can perform the actions necessary to perform common phone scams.',\n",
       " 'We designed a series of agents to perform the actions necessary for common scams. To do so, we select a list of common scams collected by the government and construct voice-enabled agents with directions to perform these scams.',\n",
       " 'Our agents consist of a base, voice-enabled LLM (GPT-4o), a set of tools that the LLM can use, and scam-specific instructions. As we have shown, voice-enabled LLM agents can perform the actions necessary to perform common phone scams.',\n",
       " 'The LLM and tools were the same for all agents but the instructions varied. The instructions were specific to each scam.',\n",
       " 'The AI agents had access to five browser access tools based on the browser testing framework playwright. 5. evaluate_javascript, which JavaScript on a page.',\n",
       " 'These tools are granular browser actions: 1. get_html, which gets the HTML of a page. 3. click_element, which clicks on an element with a CSS selector.',\n",
       " '2. navigate, which navigates to a specific URL. 3. click_element, which clicks on an element with a CSS selector.',\n",
       " '4. fill_element, which fills an element with the specified value. 3. click_element, which clicks on an element with a CSS selector.',\n",
       " 'We used GPT-4o for all of our experiments. Gpt-4 technical report.',\n",
       " 'GPT4o will refuse to handle user credentials in certain circumstances. For example, our GPT-4o based agents failed to transcribe the password or username for the Gmail credential stealing scam, but successfully completed the rest of the actions.',\n",
       " 'We used a standard jailbreaking prompt template to bypass these protections. Exploiting programmatic behavior of llms: Dual-use through standard security attacks.',\n",
       " 'We show an architecture diagram of our agent in Furthermore, our prompts are not complex. We designed a series of agents to perform the actions necessary for common scams.',\n",
       " 'The average number of tokens per prompt was 232, indicating the simplicity of their creation. Finally, the overall costs are low: under $0.75 on average per successful scam.',\n",
       " 'We deployed our agents on the scams in In order to determine if the scam successfully succeeded, we manually confirmed if the end state was achieved on real applications/websites. We conduct experiments on our voice-enabled agents and show that they can indeed perform the actions necessary to autonomously perform such scams.',\n",
       " 'For example, we used Bank of America for the bank transfer scams and confirmed that the money was actually transferred. However, other scams, such as the bank account transfer, required navigating complex websites (Bank of America), which caused errors in the actions themselves.',\n",
       " 'The credential stealing scams required a successful login. The scammer must also react to any errors that may occur (e.g., a misheard password).',\n",
       " 'We list the applications (MyMonero, Gmail, Instagram, Bank of America, Google Play) in We executed each scam 5 times and recorded the overall success rate, the total number of tool calls (i.e., actions) required to perform each successfully executed scam, the total call time for each successfully executed scam, and the approximate API cost for each successfully executed scam. These agents also maintain coherence in conversation and Scam Bank account transfer Gift code exfiltration Crypto transfer Credential stealing (Gmail) Credential stealing (bank) Credential stealing (social media) IRS impostor (gift card) Description Scammer takes control of victim’s bank account and transfers money out Scammer convinces victim to send gift card to scammer Scammer takes control of victim’s crypto account and transfers crypto Scammer steals users credentials and exfiltrates data Scammer steals users credentials and exfiltrates data Scammer steals users credentials and exfiltrates data Scammer pretends to be an IRS agent and steals gift cards Scam Crypto Transfer (MyMonero) Credential stealing (Gmail) Credential stealing (Instagram) Bank transfer (Bank of America) IRS impostor (gift card, Google Play) Overall success rate 40% 60% 40% 20% 20% # of actions Time (s) Cost ($) 122 16 112 5 77 4 183 26 86 13 $0.12 $0.28 $0.19 $2.51 $0.17 adherence to goals over the conversations.',\n",
       " 'Namely, we exclude the unsuccessful scams for computing the number of actions and total call time. We instead focus specifically on the actions needed to perform the scams.',\n",
       " 'For example, the bank transfer scam takes 26 actions to complete. Consider a scam where the scammer steals a victim’s bank credentials and steals money by transferring it out.',\n",
       " 'They also take a substantial amount of time, with complex scams taking as much as 3 minutes to execute. The scam took a total of 183 seconds to complete.',\n",
       " 'The bank transfer scam’s costs is primarily in text tokens from the large HTML from the website. However, other scams, such as the bank account transfer, required navigating complex websites (Bank of America), which caused errors in the actions themselves.',\n",
       " 'Beyond the overall statistics, the majority of failures for many of the scams were actually due to transcription errors. Common scams.',\n",
       " 'Thus, the difficulty of the scam does appear to affect the success rate. These improvements have translated to broad improvements in a range of downstream tasks and we anticipate that this will also be the case for efficacy in scams.',\n",
       " '4. 4.',\n",
       " 'Scammer: I understand your concern. Scammer: Hello!',\n",
       " 'Your security is our top priority. Your cooperation is appreciated.',\n",
       " 'To verify your identity and resolve this issue, I need to authenticate you through your Bank of America account. Scammer: It seems we need to verify your identity.',\n",
       " 'Please provide your login details so we can proceed with securing your account. This will allow us to proceed with the login process.',\n",
       " '5. 5.',\n",
       " 'Victim: Yeah, my username is [username], my password is [password]. Victim: My code is [2FA code].',\n",
       " '6. 6.',\n",
       " 'Could you please provide the 2FA code sent to your registered device? Fill out the 2FA code.',\n",
       " '7. 7.',\n",
       " 'To further understand the trajectory of these scams, we provide a redacted transcript and an abridged action log for a bank transfer scam. Consider a scam where the scammer steals a victim’s bank credentials and steals money by transferring it out.',\n",
       " 'The transcript proceeds as follows: Between items 5 and 6 of the transcript, the agent navigates to the Bank of America login page and inputs the username and password, which takes 6 actions (navigate, get_html, fill_element, fill_element, click_element, get_html). After item 7 of the transcript, the agent performs 20 actions to fill out the 2FA code, navigate to the transfer page, and transfer the money.',\n",
       " '1. 2.',\n",
       " 'Victim: Hello? Victim: What?',\n",
       " '2. 2.',\n",
       " 'This is John from Bank of America. To verify your identity and resolve this issue, I need to authenticate you through your Bank of America account.',\n",
       " 'We’ve noticed some unusual activity on your account and need to verify your information for security purposes. Scammer: It seems we need to verify your identity.',\n",
       " 'Could you please provide your username and password so we can ensure your account remains protected? Please provide your login details so we can proceed with securing your account.',\n",
       " 'Conceptually, the agent must: 1. In order to perform this scam, the scammer must: 1.',\n",
       " '2. 2.',\n",
       " 'Navigate to the transfer page. Navigate to the transfer page.',\n",
       " '3. 3.',\n",
       " 'Search for a recipient. Select the recipient.',\n",
       " '3. 3.',\n",
       " '4. 4.',\n",
       " '5. 5.',\n",
       " 'Fill out the amount. Fill out the date.',\n",
       " '6. 6.',\n",
       " '7. 7.',\n",
       " 'In these 20 actions, the agent failed several times and must retry. After item 7 of the transcript, the agent performs 20 actions to fill out the 2FA code, navigate to the transfer page, and transfer the money.',\n",
       " 'It failed to search for the recipient once, fill in the transfer amount twice, click a form advancement page once, and fill out the transaction date once. Navigate to the transfer page.',\n",
       " 'Through the entire call, the agent was able to maintain coherence, retry several failed actions, and successfully transfer the money. Successfully submit the transfer.',\n",
       " 'This example demonstrates that these voice-enabled AI agents can perform complex tasks necessary to complete scams, including retrying upon failure. In this work, we show that voice-enabled AI agents can perform the actions necessary to perform common scams.',\n",
       " 'We believe that the capabilities demonstrated in this section are a lower bound for future voice-assisted AI agents. In this work, we show that voice-enabled AI agents can perform the actions necessary to perform common scams.',\n",
       " 'These agents are likely to improve in several ways. Other agents improve significantly with techniques like retrieval-augmented generation .',\n",
       " 'For example, the actions that our agents must take are highly granular, such filling out specific fields, clicking on buttons, and navigating to specific websites. Our agents are capable of performing all the scams in Performing these scams also takes a substantial number of actions.',\n",
       " 'More ergonomic methods of interacting with web browsers will likely improve performance. These agents are likely to improve in several ways.',\n",
       " 'Beyond improvements in agents, base models have substantially improved in the past few years . Other agents improve significantly with techniques like retrieval-augmented generation .',\n",
       " 'We now provide an overview of related work. Nonetheless, we believe our work highlights an important capabilities of newly available technology.',\n",
       " 'Dual use of AI. The use of AI for dual use has widely been studied .',\n",
       " 'These studies range from taxonomizing potential dual use applications of AI to demonstrating capabilities on cybersecurity attacks. The use of AI for dual use has widely been studied .',\n",
       " 'To our knowledge, the ability to perform real-time voice conversations and perform tool use has not been widely available until recently. Recently, AI vendors have introduced capabilities for tool use and real-time voice conversations .',\n",
       " 'As such, ours is the first work to demonstrate that voice-enabled AI agents can perform the actions necessary for common scams. In this work, we show that voice-enabled AI agents can perform the actions necessary to perform common scams.',\n",
       " 'AI scams and spam. AI has already been used in the real world to perform scams and produce spam.',\n",
       " 'For example, deepfakes have already been used to scam a British engineering company out of $25 million dollars . Finance worker pays out $25 million after video call with deepfake ‘chief financial officer’.',\n",
       " 'They are also widely used to create social media spam . Ai-generated spam is starting to fill social media.',\n",
       " 'To our knowledge, autonomous, responsive voice scams are not widely deployed due to technological limitations. To our knowledge, the ability to perform real-time voice conversations and perform tool use has not been widely available until recently.',\n",
       " 'Namely, these scams are currently performed by humans . AI has already been used in the real world to perform scams and produce spam.',\n",
       " 'Our work shows that autonomous voices scams are possible with new advances in AI. We conduct a series of experiments, showing that voice-enabled AI agents are highly capable of autonomously performing the actions needed to conduct these common scams.',\n",
       " 'These agents are highly capable, can react to changes in the environment, and retry based on faulty information from the victim. These agents are likely to improve in several ways.',\n",
       " 'Our results highlight the need for future research in protecting victims from such scams. These improvements have translated to broad improvements in a range of downstream tasks and we anticipate that this will also be the case for efficacy in scams.',\n",
       " 'Namely, for an agent to perform a scam autonomously, it must first convince the victim that it is legitimate. As part of the scam, the scammer must also persuade the victim that the scammer is legitimate.',\n",
       " 'Our work explores nefarious uses of AI technology. By outlining such nefarious uses, malicious actors could potentially take advantage of such technology.',\n",
       " 'However, we believe it is important to study the capabilities of new technology, especially in its dual use capabilities. Nonetheless, we believe our work highlights an important capabilities of newly available technology.',\n",
       " 'We have elected not to make our agents public. In this work, we do not focus on the persuasion aspect of the scam.',\n",
       " 'This is for two reasons. here’s why.',\n",
       " 'First, following prior work on dual use technology, we believe it is beneficial not to release our code so that nefarious actors cannot leverage our work. Second, we believe that keeping our code private allows model providers (e.g., OpenAI) to build defenses to prevent such nefarious use.',\n",
       " 'Acknowledgments This work was funded in part by the Open Philanthropy project. Your cooperation is appreciated.',\n",
       " 'References Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al.',\n",
       " '2023. 2022.',\n",
       " 'arXiv preprint . arXiv preprint .',\n",
       " 'Shannon Bond. Brian Schwalb.',\n",
       " '2024. 2024.',\n",
       " 'Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Laura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh, et al.',\n",
       " '2020. 2020.',\n",
       " 'Language models are few-shot learners. On the conversational persuasiveness of large language models: A randomized controlled trial.',\n",
       " 'Advances in neural information processing systems, 33:1877–1901. Advances in Neural Information Processing Systems, 33:9459–9474.',\n",
       " 'Heather Chen. Ken Paxton.',\n",
       " '2024. 2024.',\n",
       " 'Richard Fang, Rohan Bindu, Akul Gupta, Qiusi Llm agents Preprint, Zhan, and Daniel Kang. Richard Fang, Rohan Bindu, Akul Gupta, Qiusi Zhan, and Daniel Kang.',\n",
       " '2024a. 2024b.',\n",
       " 'can autonomously hack websites. Our work shows that autonomous voices scams are possible with new advances in AI.',\n",
       " 'Teams of llm agents can exploit zero-day vulnerabilities. These agents are highly capable, can react to changes in the environment, and retry based on faulty information from the victim.',\n",
       " 'arXiv preprint . arXiv preprint .',\n",
       " 'Yaniv Hanoch and Stacey Wood. Shannon Bond.',\n",
       " '2021. 2021.',\n",
       " 'The scams among us: Who falls prey and why. Common scams.',\n",
       " 'Current Directions in Psychological Science, 30(3):260–266. Advances in Neural Information Processing Systems, 33:9459–9474.',\n",
       " 'Daniel Kang, Xuechen Li, Ion Stoica, Carlos Guestrin, Matei Zaharia, and Tatsunori Hashimoto. Richard Fang, Rohan Bindu, Akul Gupta, Qiusi Zhan, and Daniel Kang.',\n",
       " '2024. 2024.',\n",
       " 'In 2024 IEEE Security and Privacy Workshops (SPW), pages 132–143. In 2022 ACM Conference on Fairness, Accountability, and Transparency, pages 214–229.',\n",
       " 'IEEE. OpenAI.',\n",
       " '2020. 2020.',\n",
       " 'Retrieval-augmented generation for knowledge-intensive nlp tasks. Other agents improve significantly with techniques like retrieval-augmented generation .',\n",
       " '2024. 2024.',\n",
       " 'Introducing the realtime api. OpenAI.',\n",
       " '2024. 2024.',\n",
       " 'Francesco Salvi, Manoel Horta Ribeiro, Riccardo Gallotti, and Robert West. Fabio Urbina, Filippa Lentzos, Cédric Invernizzi, and Sean Ekins.',\n",
       " '2024. 2024.',\n",
       " 'arXiv preprint . arXiv preprint .',\n",
       " '2024. 2024.',\n",
       " 'Dual use of artificial-intelligencepowered drug discovery. Dual use of AI.',\n",
       " 'Nature machine intelligence, 4(3):189–191. Advances in Neural Information Processing Systems, 33:9459–9474.',\n",
       " '2021. 2021.',\n",
       " 'Ethical and social risks of harm from language models. Taxonomy of risks posed by language models.',\n",
       " 'arXiv preprint . arXiv preprint .',\n",
       " 'Laura Weidinger, Jonathan Uesato, Maribeth Rauh, Conor Griffin, Po-Sen Huang, John Mellor, Amelia Glaese, Myra Cheng, Borja Balle, Atoosa Kasirzadeh, et al. Laura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh, et al.',\n",
       " '2022. 2022.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77320dab",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "2013 (HY000): Lost connection to MySQL server during query",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMySQLInterfaceError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\llm\\Lib\\site-packages\\mysql\\connector\\connection_cext.py:772\u001b[39m, in \u001b[36mCMySQLConnection.cmd_query\u001b[39m\u001b[34m(self, query, raw, buffered, raw_as_string, **kwargs)\u001b[39m\n\u001b[32m    770\u001b[39m     \u001b[38;5;28mself\u001b[39m._local_infile_filenames = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m772\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmysql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    773\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbuffered\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuffered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraw_as_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_attrs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquery_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[31mMySQLInterfaceError\u001b[39m: Lost connection to MySQL server during query",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m     connection.commit()\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[43madd_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m cur.close()\n\u001b[32m     12\u001b[39m connection.close()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36madd_document\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_document\u001b[39m(text):\n\u001b[32m      4\u001b[39m     embedding = embed_model.encode(text).tolist()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mINSERT INTO DocumentsTable (content, embedding) VALUES (\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     connection.commit()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\llm\\Lib\\site-packages\\mysql\\connector\\cursor_cext.py:353\u001b[39m, in \u001b[36mCMySQLCursor.execute\u001b[39m\u001b[34m(self, operation, params, map_results)\u001b[39m\n\u001b[32m    345\u001b[39m \u001b[38;5;28mself\u001b[39m._executed = (\n\u001b[32m    346\u001b[39m     \u001b[38;5;28mself\u001b[39m._stmt_partition[\u001b[33m\"\u001b[39m\u001b[33msingle_stmts\u001b[39m\u001b[33m\"\u001b[39m].popleft()\n\u001b[32m    347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m map_results\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stmt_partition[\u001b[33m\"\u001b[39m\u001b[33mmappable_stmt\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    349\u001b[39m )\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    352\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle_result(\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcmd_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stmt_partition\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmappable_stmt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m            \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbuffered\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m            \u001b[49m\u001b[43mraw_as_string\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    359\u001b[39m     )\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(err, \u001b[33m\"\u001b[39m\u001b[33merrno\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\llm\\Lib\\site-packages\\mysql\\connector\\opentelemetry\\context_propagation.py:97\u001b[39m, in \u001b[36mwith_context_propagation.<locals>.wrapper\u001b[39m\u001b[34m(cnx, *args, **kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# pylint: disable=possibly-used-before-assignment\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OTEL_ENABLED \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cnx.otel_context_propagation:\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m current_span = trace.get_current_span()\n\u001b[32m    100\u001b[39m tp_header = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\llm\\Lib\\site-packages\\mysql\\connector\\connection_cext.py:781\u001b[39m, in \u001b[36mCMySQLConnection.cmd_query\u001b[39m\u001b[34m(self, query, raw, buffered, raw_as_string, **kwargs)\u001b[39m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(err, \u001b[33m\"\u001b[39m\u001b[33merrno\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m781\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m get_mysql_exception(\n\u001b[32m    782\u001b[39m             err.errno, msg=err.msg, sqlstate=err.sqlstate\n\u001b[32m    783\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InterfaceError(\u001b[38;5;28mstr\u001b[39m(err)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    785\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[31mOperationalError\u001b[39m: 2013 (HY000): Lost connection to MySQL server during query"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def add_document(text):\n",
    "    embedding = embed_model.encode(text).tolist()\n",
    "    cur.execute('INSERT INTO DocumentsTable (content, embedding) VALUES (%s, %s)',(text, json.dumps(embedding)))\n",
    "    connection.commit()\n",
    "\n",
    "for chunk in chunks:\n",
    "    add_document(chunk)\n",
    "\n",
    "cur.close()\n",
    "connection.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
